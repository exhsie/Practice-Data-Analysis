---
title: "Multiple linear regression analysis with Prestige"
output: rmarkdown::github_document
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE)
```

This analysis follows the tutorial by [Felipe Rego](https://rpubs.com/FelipeRego/MultipleLinearRegressionInRFirstSteps) on RPubs for the most part, using the Prestige dataset.

We are running a multiple linear regression to predict average income in 1971, Canada, from the average number of years of education, the percentage of women in an occupation and the prestige of the occupation as indicated by a social survey conducted in the mid-1960s.

```{r load libraries}
library("car")
library("corrplot")
library("ggplot2")
```

```{r explore data, check for NA & subset, include = FALSE}
head(Prestige)
str(Prestige)
summary(Prestige)
sapply(Prestige,function(x) sum(is.na(x)))
which(is.na(Prestige), arr.ind = TRUE)
newdata = Prestige[,(1:4)]
```

```{r generate descriptive statistics}
Des.stats <- function(x) c(Mean=mean(x), SD=sd(x), N=length(x))
as.data.frame(t(round(sapply(newdata, Des.stats),3)))
```

```{r checking distributions}
ggplot(data=newdata, aes(newdata$income)) + 
  geom_histogram(aes(y =..density..),
                 col="black", 
                 fill="blue", 
                 alpha = .2) + 
  geom_density(col=2) + 
  labs(title="Histogram of Average Income ($)",
       x = "Average Income ($)",
       y = "Density")

ggplot(data=newdata, aes(newdata$prestige)) + 
  geom_histogram(aes(y =..density..),
                 binwidth = 3,
                 col="black", 
                 fill="blue", 
                 alpha = .2) + 
  geom_density(col=2) + 
  labs(title="Histogram of Prestige Scores",
       x = "Prestige Scores",
       y = "Density")

ggplot(data=newdata, aes(newdata$education)) + 
  geom_histogram(aes(y =..density..), 
                 binwidth = 0.4,
                 col="black", 
                 fill="blue", 
                 alpha = .2) + 
  geom_density(col=2) + 
  labs(title="Histogram of years of Education",
       x = "Average number of years of Education",
       y = "Density")

ggplot(data=newdata, aes(newdata$women)) + 
  geom_histogram(aes(y =..density..), 
                 binwidth = 3,
                 col="black", 
                 fill="blue", 
                 alpha = .2) + 
  geom_density(col=2) + 
  labs(title="Histogram of Percentage of Women",
       x = "Percentage of Women",
       y = "Density")
```

It appears that income and prestige have a right skewed distribution. A logarithmic transformation may be suitable to correct skewness.

```{r scatterplot to view the relationship}
plot(newdata, pch=16, col="blue", main="Matrix Scatterplot of Income, Education, Women and Prestige")
```

From the matrix plot, there appears to be a positive curvilinear relationship between education and income, education and prestige of occupation, prestige of occupation and income and a negative curvilinear relationship between percentage of women and income. It also appears that there may be a few outliers to be considered for removal.

```{r fit model, include = FALSE}
model = lm(income ~ education + prestige + women, data=newdata)
summary(model)
Anova(model)
```

Examining the model summary, multiple R^2 = 0.6432, AdjR^2 = 0.6323 so the model accounts for 63.2% of the variance in average income. Similarly, the Anova table shows a significant improvement in sum of squares with the prestige and women variables (p<0.001) but not for education (p>0.05).

```{r}
## regression assumption of multicollinearity, correlation should be<0.8

## test for vif which should be <5
```

```{r testing for multicollinearity with correlation matrix plot}
newdatacor = cor(newdata[1:4])
corrplot(newdatacor, method = "number")
```

```{r testing with vif}
vif(model)
```

As shown by the correlation matrix, education and prestige are highly correlated (r = 0.85). However, vif<5 for all variables which suggests that multicollinearity is not an issue although prestige has a vif value of 4.03 and education has a vif value of 3.99 which suggests moderate correlation. Hence, we will retain all variables.

```{r function for plotting model residuals}
plot1only = function(x) plot(x, pch = 16, which = 1)
```

```{r residuals plot}
plot1only(model)
```

```{r testing for normality, include = FALSE}
shapiro.test(residuals(model))
```

Residuals plot shows a general downward trend with a sloping loess line and an uneven distribution above and below horizontal zero, suggesting heteroscedasticity. Testing the residuals for normality with Shapiro-Wilk confirms that the residuals are not normally distributed, W(102) = 0.765, p<0.001 and that a non-linear procedure might be more suitable.

```{r}
## studentized deleted residuals have a t-distribution. By comparing variables against this distribution with a Bonferroni correction of a = 0.05, we can find outliers
```

```{r function to detect outliers with SDR}
SDRcheck = function(x, N=N, p=p){
  sdr = abs(round(rstudent(x), 3))
  which(sdr>abs(qt(0.05/(N*2),(N-1-p))), arr.ind = TRUE)
}
```

```{r}
SDRcheck(model, N=102, p=3)
```

Studentized deleted residuals suggests physicians and general managers as outliers with unusual Y values.

```{r}
cooksd.all = cooks.distance(model)
which(cooksd.all>(3*mean(cooksd.all)))
```

While Cook's D suggests an additional 3 cases of lawyers, ministers and osteopaths.chiropractors as outliers with unusual x and y values.

```{r}
newdata[c("physicians","general.managers","lawyers","ministers","osteopaths.chiropractors"),]
```

```{r average of all columns}
sapply(newdata, mean)
```

The incomes for physicians, general managers, lawyers and osteopath/chiropractors are clearly much higher than the average of $6797.90; whereas the percentage of women in these occupations is much lower than the average of 29.0% in this dataset. We will therefore remove these 5 cases where women are underrepresented in high income occupations (excepting ministers who draw an average income).

```{r remove outliers}
data.rm.outliers = newdata[-c(2,17,20,24,26),]
```

```{r check model, include = FALSE}
model2 = lm(income ~ prestige + women + education, data=data.rm.outliers)
summary(model2)
Anova(model2)
```

```{r}
plot1only(model2)
```

Model 2 displays a better fit; multiple R^2 = 0.8072 and AdjR^2 = 0.8009, accounting for 80.1% of the variance in average income. The Anova table shows a significant improvement in sum of squares for all three variables (p<0.05). However, due to the non-linear nature of the data, the residuals plot still shows an uneven distribution  with a slightly sloping loess line.

To test for a better fit while continuing with the linear procedure, we will apply a logarithmic transformation to income and prestige.

```{r}
## transform data to remove heteroscedasticity e.g. square root variables, squaring variables, taking log of DV
```

```{r test, include = FALSE}
model3 = lm(log(income) ~ prestige + women + education, 
            data = data.rm.outliers)
summary(model3)
Anova(model3)
```

```{r}
plot1only(model3)
```

```{r testtest, include = FALSE}
model4 = lm(log(income) ~ log(prestige) + women + education, 
            data = data.rm.outliers)
summary(model4)
Anova(model4)
```

```{r}
plot1only(model4)
```

However, Models 3 and 4 have reduced AdjR^2 values of 0.7359 and 0.7793 respectively without achieving a more normally distributed residuals plot. Model 2 therefore has the best fit and the final model is:

income = 686.883 + (prestige * 97.753) - (women * 46.172) + (education * 234.170)

For each increase in prestige of the occupation, income increases by $97.75.
For each increase in percentage of women in the occupation, income decreases by $46.17.
For each increase of one year of education, income increases by $234.17.
